{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kithd5EdzaRJ"
   },
   "source": [
    "# Generate Bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1676916017728,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "aZBO1myjzerk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import dirichlet, multinomial\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "\n",
    "class InsufficientDataPoints(Exception):\n",
    "\tpass\n",
    "\n",
    "\n",
    "class InvalidAlpha(Exception):\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1676916017728,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "fsbslK3JzGo4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_bags_dirichlet(train_y, num_classes, bag_size, num_bags, alpha):\n",
    "\tif len(alpha) != num_classes:\n",
    "\t\traise InvalidAlpha(\"the dirichlet distribution's parameter should have length equal to num_classes\")\n",
    "\n",
    "\tmultinomial_param = dirichlet(alpha, num_bags)\n",
    "\tbag_arr = np.zeros(multinomial_param.shape)\n",
    "\tfor row_num in range(bag_arr.shape[0]):\n",
    "\t\tbag_arr[row_num, :] = multinomial(bag_size, multinomial_param[row_num, :])\n",
    "\tbag_arr = bag_arr.astype(np.int64)\n",
    "\treturn _make_bags_counts(train_y, num_classes, bag_arr)\n",
    "\n",
    "def _make_bags_counts(train_y, num_classes, lp_arr):\n",
    "\ttrain_y = np.array(train_y, dtype=np.int64)  # y has to be integers starting from 0\n",
    "\n",
    "\t# first need to verify the number of data points\n",
    "\ttotal_label_counts = {}\n",
    "\tfor label in range(num_classes):\n",
    "\t\ttotal_label_counts[int(label)] = (train_y == label).astype(int).sum()\n",
    "\texpected_label_counts = {i: np.sum(lp_arr[:, i]) for i in range(num_classes)}\n",
    "\tfor label in range(num_classes):\n",
    "\t\tif total_label_counts[label] < expected_label_counts[label]:\n",
    "\t\t\traise InsufficientDataPoints(\"Requested data points > total number of data points\")\n",
    "\t# done checking\n",
    "\n",
    "\tlabel2indices = {}\n",
    "\tfor i in range(len(train_y)):\n",
    "\t\tlabel = int(train_y[i])\n",
    "\t\tif label not in label2indices.keys():\n",
    "\t\t\tlabel2indices[label] = set({})\n",
    "\t\tlabel2indices[label].add(i)\n",
    "\n",
    "\tbag2indices, bag2size, bag2prop = {}, {}, {}\n",
    "\tfor bag_idx in range(lp_arr.shape[0]):\n",
    "\t\tbag2indices[bag_idx] = []\n",
    "\t\tfor label in range(num_classes):\n",
    "\t\t\tclass_indices = random.sample(list(label2indices[label]), lp_arr[bag_idx, label])\n",
    "\t\t\tlabel2indices[label] -= set(class_indices)\n",
    "\t\t\tbag2indices[bag_idx].extend(class_indices)\n",
    "\t\tbag2size[bag_idx] = len(bag2indices[bag_idx])\n",
    "\t\tbag2prop[bag_idx] = np.zeros((num_classes,))\n",
    "\t\tfor j in range(num_classes):\n",
    "\t\t\tbag2prop[bag_idx][j] = np.sum(train_y[bag2indices[bag_idx]] == j) / bag2size[bag_idx]\n",
    "\treturn bag2indices, bag2size, bag2prop\n",
    "\n",
    "def truncate_data(data, bag2indices):\n",
    "\tidx_list = []\n",
    "\tfor bag_id in bag2indices.keys():\n",
    "\t\tidx_list.extend(bag2indices[bag_id])\n",
    "\tidx_list.sort()\n",
    "\tdata_truncated = data[idx_list]\n",
    "\tidx2new = {idx_list[i]: i for i in range(len(idx_list))}\n",
    "\tbag2new = {bag_id: list(map(idx2new.get, bag2indices[bag_id])) for bag_id in bag2indices.keys()}\n",
    "\treturn data_truncated, bag2new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3044,
     "status": "ok",
     "timestamp": 1676916020771,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "dKH-mhR9zrP1",
    "outputId": "77f5ff27-2ebb-4d9a-9eee-09cdb477b397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# download the fully labeled data\n",
    "import torchvision\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\".\", train=True, download=True)\n",
    "labels = train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3462,
     "status": "ok",
     "timestamp": 1676916024232,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "Bj_MH1lM0C1A"
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "bag_size = 32\n",
    "n_bags = 1000\n",
    "bag2indices, bag2size, bag2prop = make_bags_dirichlet(labels, num_classes=n_classes, bag_size=bag_size, num_bags=n_bags, alpha = tuple([1 for _ in range(n_classes)]))\n",
    "training_data, bag2indices = truncate_data(train_dataset.data, bag2indices)\n",
    "\n",
    "# bag2indices maps a bag id to indices of feature vectors\n",
    "# bag2size maps a bag id to its size\n",
    "# bag2prop maps a bag id to its label proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ize1Qj0R2UM_"
   },
   "source": [
    "# Model and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676916024233,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "7o1uz7eH2fM8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Sampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1676916024335,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "kCa5d9ya1nDB"
   },
   "outputs": [],
   "source": [
    "# helper functions to load the data for training\n",
    "\n",
    "def truncate_data_group(x, y, instance2group):\n",
    "\tidx_list = []\n",
    "\tfor i in range(x.shape[0]):\n",
    "\t\tif instance2group[i] != -1:\n",
    "\t\t\tidx_list.append(i)\n",
    "\tx_truncated = x[idx_list]\n",
    "\ty_truncated = y[idx_list]\n",
    "\tidx2new = {idx_list[i]: i for i in range(len(idx_list))}\n",
    "\tinstance2group_new = {}\n",
    "\tfor old, new in idx2new.items():\n",
    "\t\tinstance2group_new[new] = instance2group[old]\n",
    "\tnew2idx = {idx2new[idx]: idx for idx in idx2new.keys()}\n",
    "\treturn x_truncated, y_truncated, instance2group_new, new2idx\n",
    "\n",
    "\n",
    "class LLPFC_DATASET_BASE(torch.utils.data.Dataset):\n",
    "\tdef __init__(self, data, noisy_y, group2transition, instance2weight, instance2group, transform):\n",
    "\t\tself.data, self.noisy_y, self.instance2group, self.new2idx = truncate_data_group(data, noisy_y, instance2group)\n",
    "\t\tself.group2transition = group2transition\n",
    "\t\tself.instance2weight = instance2weight\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\n",
    "class FORWARD_CORRECT_CIFAR10(LLPFC_DATASET_BASE):\n",
    "\tdef __getitem__(self, index):\n",
    "\t\timg, y_ = self.data[index], self.noisy_y[index]\n",
    "\t\ttrans_m = self.group2transition[self.instance2group[index]]\n",
    "\t\tweight = self.instance2weight[self.new2idx[index]]\n",
    "\t\timg = Image.fromarray(img)\n",
    "\t\tif self.transform is not None:\n",
    "\t\t\timg = self.transform(img)\n",
    "\t\treturn img, int(y_), torch.tensor(trans_m, dtype=None), weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOOX3vRR9-iY"
   },
   "source": [
    "We use the resnet implementation from https://github.com/kevinorjohn/LLP-VAT.\n",
    "You can use other networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1676916025159,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "o51N1TPL2iCQ"
   },
   "outputs": [],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2020 Kuen-Han Tsai\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def wide_resnet_d_w(d, w, **kwargs):\n",
    "    net = WideResNet(d, w, **kwargs)\n",
    "    net.apply(conv_init)\n",
    "    return net\n",
    "\n",
    "\n",
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\" add gasussian noise into feature \"\"\"\n",
    "    def __init__(self, std):\n",
    "        super(GaussianNoise, self).__init__()\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x):\n",
    "        zeros_ = torch.zeros_like(x)\n",
    "        n = torch.normal(zeros_, std=self.std)\n",
    "        return x + n\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=True)\n",
    "\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class WideBasic(nn.Module):\n",
    "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
    "        super(WideBasic, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes,\n",
    "                               planes,\n",
    "                               kernel_size=3,\n",
    "                               padding=1,\n",
    "                               bias=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes,\n",
    "                               planes,\n",
    "                               kernel_size=3,\n",
    "                               stride=stride,\n",
    "                               padding=1,\n",
    "                               bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes,\n",
    "                          planes,\n",
    "                          kernel_size=1,\n",
    "                          stride=stride,\n",
    "                          bias=True), )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes, in_channel, image_size, return_features=False):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        if image_size == 32:  # CIFAR10, SVHN\n",
    "            self.pool_size = 8\n",
    "        elif image_size == 28:  # EMNIST\n",
    "            self.pool_size = 7\n",
    "        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth - 4) // 6\n",
    "        k = widen_factor\n",
    "\n",
    "        print('| Wide-Resnet %dx%d' % (depth, k))\n",
    "        nStages = [16, 16 * k, 32 * k, 64 * k]\n",
    "\n",
    "        self.conv1 = conv3x3(in_channel, nStages[0])\n",
    "        self.layer1 = self._wide_layer(WideBasic,\n",
    "                                       nStages[1],\n",
    "                                       n,\n",
    "                                       dropout_rate,\n",
    "                                       stride=1)\n",
    "        self.layer2 = self._wide_layer(WideBasic,\n",
    "                                       nStages[2],\n",
    "                                       n,\n",
    "                                       dropout_rate,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._wide_layer(WideBasic,\n",
    "                                       nStages[3],\n",
    "                                       n,\n",
    "                                       dropout_rate,\n",
    "                                       stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
    "        self.linear = nn.Linear(nStages[3], num_classes)\n",
    "\n",
    "        self.return_features = return_features\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, self.pool_size)\n",
    "        features = out.view(out.size(0), -1)\n",
    "        out = self.linear(features)\n",
    "        if self.return_features:\n",
    "            return out, features\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpukHVHk3EUr"
   },
   "source": [
    "# Grouping funcions for LLPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676916025159,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "xIOnwTsI3Lo9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.special import factorial\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint\n",
    "\n",
    "\n",
    "class InvalidChoiceOfWeights(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class InvalidChoiceOfNoisyPrior(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676916025159,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "o9lJpY4q24kY"
   },
   "outputs": [],
   "source": [
    "def approx_noisy_prior(gamma_m, clean_prior):  # use the solution as noisy prior for LLPFC-approx\n",
    "    def ls_error(x, A, b):\n",
    "        return 0.5 * np.sum((np.matmul(A, x) - b) ** 2)\n",
    "\n",
    "    def grad(x, A, b):\n",
    "        return np.matmul(np.matmul(np.transpose(A), A), x) - np.matmul(np.transpose(A), b)\n",
    "\n",
    "    def hess(x, A, b):\n",
    "        return np.matmul(np.transpose(A), A)\n",
    "\n",
    "    x0 = np.random.rand(clean_prior.shape[0])\n",
    "    x0 /= np.sum(x0)\n",
    "\n",
    "    res = minimize(ls_error,\n",
    "                   x0,\n",
    "                   args=(np.transpose(gamma_m), clean_prior),\n",
    "                   method='trust-constr',\n",
    "                   jac=grad,\n",
    "                   hess=hess,\n",
    "                   bounds=Bounds(np.zeros(x0.shape), np.ones(x0.shape)),\n",
    "                   constraints=LinearConstraint(np.ones(x0.shape), np.ones(1), np.ones(1)),\n",
    "                   )\n",
    "    return res.x\n",
    "\n",
    "\n",
    "def make_a_group(num_classes, clean_prior, bag_ids, bag2prop, noisy_prior_choice):\n",
    "    bags_list = random.sample(list(bag_ids), num_classes)\n",
    "    gamma_m = np.zeros((num_classes, num_classes))\n",
    "    for row_idx in range(num_classes):\n",
    "        gamma_m[row_idx, :] = bag2prop[bags_list[row_idx]]\n",
    "    if noisy_prior_choice == 'approx':\n",
    "        noisy_prior_approx = approx_noisy_prior(np.transpose(gamma_m), clean_prior)\n",
    "    elif noisy_prior_choice == 'uniform':\n",
    "        noisy_prior_approx = np.ones((num_classes,)) / num_classes\n",
    "    else:\n",
    "        raise InvalidChoiceOfNoisyPrior(\"Unknown choice of noisy prior: %s\" % noisy_prior_choice)\n",
    "    assert np.all(noisy_prior_approx >= 0)\n",
    "    assert (np.sum(noisy_prior_approx) - 1) < 1e-4\n",
    "    clean_prior_approx = np.matmul(np.transpose(gamma_m), noisy_prior_approx)\n",
    "\n",
    "    transition_m = np.zeros((num_classes, num_classes))\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            transition_m[i, j] = gamma_m[i, j] * noisy_prior_approx[i] / clean_prior_approx[j]  # clean_prior can't be 0 in this case\n",
    "\n",
    "    if matrix_rank(transition_m) != num_classes:\n",
    "        print(\"singular transition matrix\")\n",
    "    if np.any(noisy_prior_approx < 0):\n",
    "        print(\"negative prior of noisy labels\")\n",
    "    return bags_list, noisy_prior_approx, transition_m\n",
    "\n",
    "\n",
    "def _pow_normalize(x, t):\n",
    "    \"\"\"\n",
    "    returns normalized x**t\n",
    "    this function is used to control the probability of bag assignment\n",
    "    \"\"\"\n",
    "    exp = x ** t\n",
    "    return exp / np.sum(exp, axis=0)\n",
    "\n",
    "\n",
    "def make_groups_forward(num_classes, bag2indices, bag2size, bag2prop, noisy_prior_choice, weights):\n",
    "    bag_ids = set(bag2indices.keys())\n",
    "    num_groups = len(bag_ids) // num_classes\n",
    "    assert num_groups > 0\n",
    "\n",
    "    clean_prior = np.zeros((num_classes, ))\n",
    "    for bag_id in bag2size.keys():\n",
    "        clean_prior += bag2prop[bag_id] * bag2size[bag_id]\n",
    "    clean_prior /= np.sum(clean_prior)\n",
    "\n",
    "    group2bag = {}\n",
    "    group2noisyp = {}\n",
    "    group2transition = {}\n",
    "    group_id = 0\n",
    "    groups = []\n",
    "    while len(bag_ids) >= num_classes:\n",
    "        bags_list, noisy_prior, transition_m = make_a_group(num_classes,\n",
    "                                                            clean_prior,\n",
    "                                                            bag_ids,\n",
    "                                                            bag2prop,\n",
    "                                                            noisy_prior_choice)\n",
    "        bag_ids = bag_ids - set(bags_list)\n",
    "        group2bag[group_id], group2noisyp[group_id], group2transition[group_id] = bags_list, noisy_prior, transition_m\n",
    "        groups.append(group_id)\n",
    "        group_id += 1\n",
    "    group2bag[-1] = list(bag_ids)  # bags that are not in a group\n",
    "    groups.append(-1)\n",
    "\n",
    "    instance2group = {instance_id: group_id for group_id in groups for bag_id in group2bag[group_id] for\n",
    "                      instance_id in bag2indices[bag_id]}\n",
    "\n",
    "    # calculate the weights of groups\n",
    "    if weights == 'uniform':\n",
    "        group2weights = {group_id: 1.0 for group_id, trans_m in group2transition.items()}\n",
    "    else:\n",
    "        raise InvalidChoiceOfWeights(\"Unknown way to determine weights %s, use either ch_vol or uniform\" % weights)\n",
    "\n",
    "    # set the noisy labels\n",
    "    noisy_y = -np.ones((sum([len(instances) for instances in bag2indices.values()]),))\n",
    "    instance2weight = np.zeros((sum([len(instances) for instances in bag2indices.values()]),))\n",
    "    for group_id in groups:\n",
    "        if group_id == -1:\n",
    "            continue\n",
    "\n",
    "        noisy_prior = group2noisyp[group_id]\n",
    "        noisy_prop = np.zeros((num_classes, ))\n",
    "        for noisy_class, bag_id in enumerate(group2bag[group_id]):\n",
    "            noisy_prop[noisy_class] = bag2size[bag_id]\n",
    "        noisy_prop /= np.sum(noisy_prop)\n",
    "        weights = np.divide(noisy_prior, noisy_prop)\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "        for noisy_class, bag_id in enumerate(group2bag[group_id]):\n",
    "            for instance_id in bag2indices[bag_id]:\n",
    "                noisy_y[instance_id] = noisy_class\n",
    "                instance2weight[instance_id] = weights[noisy_class] * group2weights[group_id]\n",
    "\n",
    "    return instance2group, group2transition, instance2weight, noisy_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUDlMWNj3fxX"
   },
   "source": [
    "# Train an LLPFC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676916025159,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "QE3A_NiF3NII"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "\t# test a model with fully label dataset\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\t\ttotal_loss = 0\n",
    "\t\tfor images, labels in test_loader:\n",
    "\t\t\timages = images.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\n",
    "\t\t\tprob = nn.functional.softmax(outputs, dim=1)\n",
    "\t\t\tloss = criterion(prob, labels, device)\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\treturn correct / total, total_loss / total\n",
    "\n",
    "\n",
    "def validate_model_forward(model, loss_f_val, val_loader, device):\n",
    "\tmodel.eval()\n",
    "\ttotal_loss = 0\n",
    "\ttotal = 0\n",
    "\tfor i, (images, noisy_y, trans_m, weights) in enumerate(val_loader):\n",
    "\t\ttotal_loss += compute_forward_loss_on_minibatch(model, loss_f_val, images, noisy_y, trans_m, weights, device).item()\n",
    "\t\ttotal += noisy_y.size(0)\n",
    "\treturn total_loss / total\n",
    "\n",
    "\n",
    "def train_model_forward_one_epoch(model, loss_f, optimizer, train_loader, device, epoch, scheduler):\n",
    "\t# train the model one epoch with forward correction\n",
    "\t# label input of loss_f must be an integer\n",
    "\tmodel.train()\n",
    "\ttotal_step = len(train_loader)\n",
    "\tfor i, (images, noisy_y, trans_m, weights) in enumerate(train_loader):\n",
    "\t\tloss = compute_forward_loss_on_minibatch(model, loss_f, images, noisy_y, trans_m, weights, device)\n",
    "\t\t# Backward pass\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tif (i + 1) % 100 == 0:\n",
    "\t\t\tprint('\t\t\t\tStep [{}/{}], Loss: {:.4f}'.format(i + 1, total_step, loss.item()))\n",
    "\t\tif type(scheduler) == torch.optim.lr_scheduler.CosineAnnealingWarmRestarts:\n",
    "\t\t\tscheduler.step(epoch + i / total_step)\n",
    "\tif type(scheduler) == torch.optim.lr_scheduler.MultiStepLR:\n",
    "\t\tscheduler.step()\n",
    "\telif type(scheduler) == torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "\t\tscheduler.step(validate_model_forward(model, loss_f, train_loader, device))\n",
    "\n",
    "\n",
    "def compute_forward_loss_on_minibatch(model, loss_f, images, noisy_y, trans_m, weights, device):\n",
    "\t# Move tensors to the configured device\n",
    "\timages = images.to(device)\n",
    "\tnoisy_y = noisy_y.to(device)\n",
    "\ttrans_m = trans_m.to(device)\n",
    "\tweights = weights.to(device)\n",
    "\t# Forward pass\n",
    "\toutputs = model(images)\n",
    "\tprob = nn.functional.softmax(outputs, dim=1)\n",
    "\tprob_corrected = torch.bmm(trans_m.float(), prob.reshape(prob.shape[0], -1, 1)).reshape(prob.shape[0], -1)\n",
    "\tloss = loss_f(prob_corrected, noisy_y, weights, device)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676916025159,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "Sx1AKbtJ33J2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.constraints import simplex\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676916025159,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "lcSgmvtC3p95"
   },
   "outputs": [],
   "source": [
    "def loss_f(x, y, weights, device, epsilon=1e-8):\n",
    "    assert torch.all(simplex.check(x))\n",
    "    x = torch.clamp(x, epsilon, 1 - epsilon)\n",
    "    unweighted = nn.functional.nll_loss(torch.log(x), y, reduction='none')\n",
    "    weights /= weights.sum()\n",
    "    return (unweighted * weights).sum()\n",
    "\n",
    "\n",
    "def loss_f_val(x, y, weights, device, epsilon=1e-8):\n",
    "    assert torch.all(simplex.check(x))\n",
    "    x = torch.clamp(x, epsilon, 1 - epsilon)\n",
    "    unweighted = nn.functional.nll_loss(torch.log(x), y, reduction='none')\n",
    "    return (unweighted * weights).sum()\n",
    "\n",
    "\n",
    "def loss_f_test(x, y, device, epsilon=1e-8):\n",
    "    x = torch.clamp(x, epsilon, 1 - epsilon)\n",
    "    return nn.functional.nll_loss(torch.log(x), y, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 648972,
     "status": "error",
     "timestamp": 1676916674129,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "tjwm03Bw3zbL",
    "outputId": "5250609c-852d-45c3-9bbb-3863c06237e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x8\n",
      "Regroup-1 Epoch-0\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.1731\n",
      "\t\t\t\tStep [200/500], Loss: 2.2123\n",
      "\t\t\t\tStep [300/500], Loss: 2.2620\n",
      "\t\t\t\tStep [400/500], Loss: 2.1908\n",
      "\t\t\t\tStep [500/500], Loss: 2.2343\n",
      "      test_error = 1.963569681930542, accuracy = 29.14%\n",
      "Regroup-1 Epoch-1\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.1883\n",
      "\t\t\t\tStep [200/500], Loss: 2.0571\n",
      "\t\t\t\tStep [300/500], Loss: 2.3043\n",
      "\t\t\t\tStep [400/500], Loss: 2.2584\n",
      "\t\t\t\tStep [500/500], Loss: 2.0798\n",
      "      test_error = 1.5885544761657715, accuracy = 43.22%\n",
      "Regroup-1 Epoch-2\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.1805\n",
      "\t\t\t\tStep [200/500], Loss: 2.0959\n",
      "\t\t\t\tStep [300/500], Loss: 2.1227\n",
      "\t\t\t\tStep [400/500], Loss: 2.0922\n",
      "\t\t\t\tStep [500/500], Loss: 2.0739\n",
      "      test_error = 1.672159308242798, accuracy = 41.02%\n",
      "Regroup-1 Epoch-3\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.2770\n",
      "\t\t\t\tStep [200/500], Loss: 2.1911\n",
      "\t\t\t\tStep [300/500], Loss: 2.1219\n",
      "\t\t\t\tStep [400/500], Loss: 2.1167\n",
      "\t\t\t\tStep [500/500], Loss: 2.0931\n",
      "      test_error = 1.7156518613815308, accuracy = 44.800000000000004%\n",
      "Regroup-1 Epoch-4\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9987\n",
      "\t\t\t\tStep [200/500], Loss: 2.0433\n",
      "\t\t\t\tStep [300/500], Loss: 2.1660\n",
      "\t\t\t\tStep [400/500], Loss: 2.0319\n",
      "\t\t\t\tStep [500/500], Loss: 2.3274\n",
      "      test_error = 1.4084928182601928, accuracy = 53.04%\n",
      "Regroup-2 Epoch-5\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.1934\n",
      "\t\t\t\tStep [200/500], Loss: 2.1412\n",
      "\t\t\t\tStep [300/500], Loss: 2.0771\n",
      "\t\t\t\tStep [400/500], Loss: 2.1132\n",
      "\t\t\t\tStep [500/500], Loss: 2.1003\n",
      "      test_error = 1.5513894357681275, accuracy = 50.6%\n",
      "Regroup-2 Epoch-6\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0136\n",
      "\t\t\t\tStep [200/500], Loss: 2.0191\n",
      "\t\t\t\tStep [300/500], Loss: 1.9617\n",
      "\t\t\t\tStep [400/500], Loss: 2.1101\n",
      "\t\t\t\tStep [500/500], Loss: 2.0500\n",
      "      test_error = 1.428963910484314, accuracy = 55.38999999999999%\n",
      "Regroup-2 Epoch-7\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9612\n",
      "\t\t\t\tStep [200/500], Loss: 2.2508\n",
      "\t\t\t\tStep [300/500], Loss: 2.0246\n",
      "\t\t\t\tStep [400/500], Loss: 2.0054\n",
      "\t\t\t\tStep [500/500], Loss: 2.0908\n",
      "      test_error = 1.4964510795593262, accuracy = 54.09%\n",
      "Regroup-2 Epoch-8\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0545\n",
      "\t\t\t\tStep [200/500], Loss: 2.0083\n",
      "\t\t\t\tStep [300/500], Loss: 2.1222\n",
      "\t\t\t\tStep [400/500], Loss: 2.0671\n",
      "\t\t\t\tStep [500/500], Loss: 2.0377\n",
      "      test_error = 1.320332025718689, accuracy = 59.019999999999996%\n",
      "Regroup-2 Epoch-9\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0789\n",
      "\t\t\t\tStep [200/500], Loss: 1.9516\n",
      "\t\t\t\tStep [300/500], Loss: 2.1260\n",
      "\t\t\t\tStep [400/500], Loss: 2.1180\n",
      "\t\t\t\tStep [500/500], Loss: 2.0849\n",
      "      test_error = 1.280653826713562, accuracy = 60.81999999999999%\n",
      "Regroup-3 Epoch-10\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0206\n",
      "\t\t\t\tStep [200/500], Loss: 2.0504\n",
      "\t\t\t\tStep [300/500], Loss: 2.2183\n",
      "\t\t\t\tStep [400/500], Loss: 1.9789\n",
      "\t\t\t\tStep [500/500], Loss: 1.9785\n",
      "      test_error = 1.6770036193847657, accuracy = 54.6%\n",
      "Regroup-3 Epoch-11\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0366\n",
      "\t\t\t\tStep [200/500], Loss: 2.0565\n",
      "\t\t\t\tStep [300/500], Loss: 1.9244\n",
      "\t\t\t\tStep [400/500], Loss: 2.1189\n",
      "\t\t\t\tStep [500/500], Loss: 1.8962\n",
      "      test_error = 1.1635678288459779, accuracy = 64.53999999999999%\n",
      "Regroup-3 Epoch-12\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9057\n",
      "\t\t\t\tStep [200/500], Loss: 2.1335\n",
      "\t\t\t\tStep [300/500], Loss: 1.9603\n",
      "\t\t\t\tStep [400/500], Loss: 1.9978\n",
      "\t\t\t\tStep [500/500], Loss: 2.1027\n",
      "      test_error = 1.2095741634368897, accuracy = 63.629999999999995%\n",
      "Regroup-3 Epoch-13\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.1328\n",
      "\t\t\t\tStep [200/500], Loss: 2.1406\n",
      "\t\t\t\tStep [300/500], Loss: 2.0686\n",
      "\t\t\t\tStep [400/500], Loss: 1.9647\n",
      "\t\t\t\tStep [500/500], Loss: 2.0626\n",
      "      test_error = 1.0633489833831786, accuracy = 68.08999999999999%\n",
      "Regroup-3 Epoch-14\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0830\n",
      "\t\t\t\tStep [200/500], Loss: 2.0012\n",
      "\t\t\t\tStep [300/500], Loss: 2.0660\n",
      "\t\t\t\tStep [400/500], Loss: 1.9657\n",
      "\t\t\t\tStep [500/500], Loss: 2.1109\n",
      "      test_error = 1.3951652284622191, accuracy = 63.0%\n",
      "Regroup-4 Epoch-15\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9281\n",
      "\t\t\t\tStep [200/500], Loss: 2.1542\n",
      "\t\t\t\tStep [300/500], Loss: 2.0211\n",
      "\t\t\t\tStep [400/500], Loss: 2.1594\n",
      "\t\t\t\tStep [500/500], Loss: 1.9553\n",
      "      test_error = 1.1916040865898132, accuracy = 66.34%\n",
      "Regroup-4 Epoch-16\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9509\n",
      "\t\t\t\tStep [200/500], Loss: 2.0479\n",
      "\t\t\t\tStep [300/500], Loss: 2.0344\n",
      "\t\t\t\tStep [400/500], Loss: 2.0272\n",
      "\t\t\t\tStep [500/500], Loss: 2.0767\n",
      "      test_error = 1.1137021909713745, accuracy = 68.47999999999999%\n",
      "Regroup-4 Epoch-17\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9128\n",
      "\t\t\t\tStep [200/500], Loss: 1.9414\n",
      "\t\t\t\tStep [300/500], Loss: 1.9931\n",
      "\t\t\t\tStep [400/500], Loss: 1.9410\n",
      "\t\t\t\tStep [500/500], Loss: 1.9742\n",
      "      test_error = 1.1832960794448852, accuracy = 67.85%\n",
      "Regroup-4 Epoch-18\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0483\n",
      "\t\t\t\tStep [200/500], Loss: 2.0088\n",
      "\t\t\t\tStep [300/500], Loss: 1.9706\n",
      "\t\t\t\tStep [400/500], Loss: 2.1303\n",
      "\t\t\t\tStep [500/500], Loss: 1.9803\n",
      "      test_error = 1.34487234249115, accuracy = 65.3%\n",
      "Regroup-4 Epoch-19\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8607\n",
      "\t\t\t\tStep [200/500], Loss: 2.0732\n",
      "\t\t\t\tStep [300/500], Loss: 2.0939\n",
      "\t\t\t\tStep [400/500], Loss: 1.9145\n",
      "\t\t\t\tStep [500/500], Loss: 1.8695\n",
      "      test_error = 1.2089732625961305, accuracy = 67.74%\n",
      "Regroup-5 Epoch-20\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0241\n",
      "\t\t\t\tStep [200/500], Loss: 2.0362\n",
      "\t\t\t\tStep [300/500], Loss: 2.0152\n",
      "\t\t\t\tStep [400/500], Loss: 1.9698\n",
      "\t\t\t\tStep [500/500], Loss: 1.9630\n",
      "      test_error = 1.127009612941742, accuracy = 70.23%\n",
      "Regroup-5 Epoch-21\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8766\n",
      "\t\t\t\tStep [200/500], Loss: 1.8519\n",
      "\t\t\t\tStep [300/500], Loss: 1.9006\n",
      "\t\t\t\tStep [400/500], Loss: 1.9881\n",
      "\t\t\t\tStep [500/500], Loss: 2.0182\n",
      "      test_error = 1.3106003440856933, accuracy = 68.54%\n",
      "Regroup-5 Epoch-22\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8389\n",
      "\t\t\t\tStep [200/500], Loss: 1.9654\n",
      "\t\t\t\tStep [300/500], Loss: 1.8809\n",
      "\t\t\t\tStep [400/500], Loss: 1.9064\n",
      "\t\t\t\tStep [500/500], Loss: 1.9359\n",
      "      test_error = 1.5946403043746948, accuracy = 65.34%\n",
      "Regroup-5 Epoch-23\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9762\n",
      "\t\t\t\tStep [200/500], Loss: 1.9961\n",
      "\t\t\t\tStep [300/500], Loss: 1.8389\n",
      "\t\t\t\tStep [400/500], Loss: 1.8587\n",
      "\t\t\t\tStep [500/500], Loss: 1.8876\n",
      "      test_error = 1.140016476917267, accuracy = 71.09%\n",
      "Regroup-5 Epoch-24\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8704\n",
      "\t\t\t\tStep [200/500], Loss: 1.9215\n",
      "\t\t\t\tStep [300/500], Loss: 2.0702\n",
      "\t\t\t\tStep [400/500], Loss: 1.8999\n",
      "\t\t\t\tStep [500/500], Loss: 1.9509\n",
      "      test_error = 1.3228194931030273, accuracy = 68.55%\n",
      "Regroup-6 Epoch-25\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7794\n",
      "\t\t\t\tStep [200/500], Loss: 1.9756\n",
      "\t\t\t\tStep [300/500], Loss: 1.8304\n",
      "\t\t\t\tStep [400/500], Loss: 1.9243\n",
      "\t\t\t\tStep [500/500], Loss: 1.9405\n",
      "      test_error = 1.0713907425880431, accuracy = 72.47%\n",
      "Regroup-6 Epoch-26\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9095\n",
      "\t\t\t\tStep [200/500], Loss: 1.9734\n",
      "\t\t\t\tStep [300/500], Loss: 1.9239\n",
      "\t\t\t\tStep [400/500], Loss: 1.9867\n",
      "\t\t\t\tStep [500/500], Loss: 1.8662\n",
      "      test_error = 1.4372225536346435, accuracy = 67.74%\n",
      "Regroup-6 Epoch-27\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9687\n",
      "\t\t\t\tStep [200/500], Loss: 2.0495\n",
      "\t\t\t\tStep [300/500], Loss: 1.7854\n",
      "\t\t\t\tStep [400/500], Loss: 1.9728\n",
      "\t\t\t\tStep [500/500], Loss: 1.9145\n",
      "      test_error = 1.1974234457969666, accuracy = 70.72%\n",
      "Regroup-6 Epoch-28\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8375\n",
      "\t\t\t\tStep [200/500], Loss: 1.9054\n",
      "\t\t\t\tStep [300/500], Loss: 1.9269\n",
      "\t\t\t\tStep [400/500], Loss: 1.9998\n",
      "\t\t\t\tStep [500/500], Loss: 1.8918\n",
      "      test_error = 1.023803022480011, accuracy = 74.00999999999999%\n",
      "Regroup-6 Epoch-29\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9102\n",
      "\t\t\t\tStep [200/500], Loss: 1.7825\n",
      "\t\t\t\tStep [300/500], Loss: 1.9911\n",
      "\t\t\t\tStep [400/500], Loss: 2.0375\n",
      "\t\t\t\tStep [500/500], Loss: 1.9628\n",
      "      test_error = 1.1037329908847808, accuracy = 72.78%\n",
      "Regroup-7 Epoch-30\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8038\n",
      "\t\t\t\tStep [200/500], Loss: 1.8825\n",
      "\t\t\t\tStep [300/500], Loss: 2.0028\n",
      "\t\t\t\tStep [400/500], Loss: 1.7567\n",
      "\t\t\t\tStep [500/500], Loss: 1.9484\n",
      "      test_error = 1.233403389930725, accuracy = 73.5%\n",
      "Regroup-7 Epoch-31\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8617\n",
      "\t\t\t\tStep [200/500], Loss: 1.7697\n",
      "\t\t\t\tStep [300/500], Loss: 2.0214\n",
      "\t\t\t\tStep [400/500], Loss: 1.9116\n",
      "\t\t\t\tStep [500/500], Loss: 1.9521\n",
      "      test_error = 1.1517505094528198, accuracy = 74.02%\n",
      "Regroup-7 Epoch-32\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8538\n",
      "\t\t\t\tStep [200/500], Loss: 1.8713\n",
      "\t\t\t\tStep [300/500], Loss: 1.8970\n",
      "\t\t\t\tStep [400/500], Loss: 1.9277\n",
      "\t\t\t\tStep [500/500], Loss: 1.8833\n",
      "      test_error = 1.1765910918235778, accuracy = 73.31%\n",
      "Regroup-7 Epoch-33\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8383\n",
      "\t\t\t\tStep [200/500], Loss: 1.8817\n",
      "\t\t\t\tStep [300/500], Loss: 1.7761\n",
      "\t\t\t\tStep [400/500], Loss: 1.9365\n",
      "\t\t\t\tStep [500/500], Loss: 2.0811\n",
      "      test_error = 1.2189959650039672, accuracy = 73.92999999999999%\n",
      "Regroup-7 Epoch-34\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 2.0874\n",
      "\t\t\t\tStep [200/500], Loss: 1.9112\n",
      "\t\t\t\tStep [300/500], Loss: 1.9117\n",
      "\t\t\t\tStep [400/500], Loss: 1.9633\n",
      "\t\t\t\tStep [500/500], Loss: 1.9635\n",
      "      test_error = 1.4128935276031493, accuracy = 70.87%\n",
      "Regroup-8 Epoch-35\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8609\n",
      "\t\t\t\tStep [200/500], Loss: 1.7625\n",
      "\t\t\t\tStep [300/500], Loss: 1.9427\n",
      "\t\t\t\tStep [400/500], Loss: 1.8350\n",
      "\t\t\t\tStep [500/500], Loss: 1.8142\n",
      "      test_error = 1.2485115666389466, accuracy = 73.98%\n",
      "Regroup-8 Epoch-36\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7292\n",
      "\t\t\t\tStep [200/500], Loss: 1.7906\n",
      "\t\t\t\tStep [300/500], Loss: 1.8262\n",
      "\t\t\t\tStep [400/500], Loss: 1.8906\n",
      "\t\t\t\tStep [500/500], Loss: 1.8911\n",
      "      test_error = 1.2198617423057556, accuracy = 74.19%\n",
      "Regroup-8 Epoch-37\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7988\n",
      "\t\t\t\tStep [200/500], Loss: 1.7190\n",
      "\t\t\t\tStep [300/500], Loss: 2.0489\n",
      "\t\t\t\tStep [400/500], Loss: 1.7981\n",
      "\t\t\t\tStep [500/500], Loss: 1.8972\n",
      "      test_error = 1.4191011587142945, accuracy = 72.77%\n",
      "Regroup-8 Epoch-38\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8821\n",
      "\t\t\t\tStep [200/500], Loss: 1.7956\n",
      "\t\t\t\tStep [300/500], Loss: 1.8672\n",
      "\t\t\t\tStep [400/500], Loss: 1.8755\n",
      "\t\t\t\tStep [500/500], Loss: 1.8816\n",
      "      test_error = 1.1761378609657287, accuracy = 75.07000000000001%\n",
      "Regroup-8 Epoch-39\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7341\n",
      "\t\t\t\tStep [200/500], Loss: 1.7244\n",
      "\t\t\t\tStep [300/500], Loss: 1.8943\n",
      "\t\t\t\tStep [400/500], Loss: 1.9171\n",
      "\t\t\t\tStep [500/500], Loss: 1.7441\n",
      "      test_error = 1.3742071601867676, accuracy = 72.57000000000001%\n",
      "Regroup-9 Epoch-40\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8013\n",
      "\t\t\t\tStep [200/500], Loss: 1.9141\n",
      "\t\t\t\tStep [300/500], Loss: 1.8894\n",
      "\t\t\t\tStep [400/500], Loss: 1.9149\n",
      "\t\t\t\tStep [500/500], Loss: 1.8246\n",
      "      test_error = 1.2754393714904786, accuracy = 74.77000000000001%\n",
      "Regroup-9 Epoch-41\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8681\n",
      "\t\t\t\tStep [200/500], Loss: 1.7723\n",
      "\t\t\t\tStep [300/500], Loss: 1.7628\n",
      "\t\t\t\tStep [400/500], Loss: 1.8683\n",
      "\t\t\t\tStep [500/500], Loss: 1.8602\n",
      "      test_error = 1.3243731711387634, accuracy = 74.59%\n",
      "Regroup-9 Epoch-42\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7497\n",
      "\t\t\t\tStep [200/500], Loss: 1.8200\n",
      "\t\t\t\tStep [300/500], Loss: 2.0071\n",
      "\t\t\t\tStep [400/500], Loss: 1.7847\n",
      "\t\t\t\tStep [500/500], Loss: 1.8770\n",
      "      test_error = 1.1017531722068787, accuracy = 76.96%\n",
      "Regroup-9 Epoch-43\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.6809\n",
      "\t\t\t\tStep [200/500], Loss: 1.8878\n",
      "\t\t\t\tStep [300/500], Loss: 1.7396\n",
      "\t\t\t\tStep [400/500], Loss: 1.9527\n",
      "\t\t\t\tStep [500/500], Loss: 1.7895\n",
      "      test_error = 1.2245034007072448, accuracy = 74.76%\n",
      "Regroup-9 Epoch-44\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8448\n",
      "\t\t\t\tStep [200/500], Loss: 1.9379\n",
      "\t\t\t\tStep [300/500], Loss: 1.8926\n",
      "\t\t\t\tStep [400/500], Loss: 1.9609\n",
      "\t\t\t\tStep [500/500], Loss: 1.8369\n",
      "      test_error = 1.0814075575828552, accuracy = 76.86%\n",
      "Regroup-10 Epoch-45\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8421\n",
      "\t\t\t\tStep [200/500], Loss: 1.7745\n",
      "\t\t\t\tStep [300/500], Loss: 1.7887\n",
      "\t\t\t\tStep [400/500], Loss: 1.8188\n",
      "\t\t\t\tStep [500/500], Loss: 1.9312\n",
      "      test_error = 1.111214563179016, accuracy = 76.13%\n",
      "Regroup-10 Epoch-46\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8290\n",
      "\t\t\t\tStep [200/500], Loss: 1.8765\n",
      "\t\t\t\tStep [300/500], Loss: 1.6995\n",
      "\t\t\t\tStep [400/500], Loss: 1.9359\n",
      "\t\t\t\tStep [500/500], Loss: 1.8000\n",
      "      test_error = 1.3799862781524659, accuracy = 73.83999999999999%\n",
      "Regroup-10 Epoch-47\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7903\n",
      "\t\t\t\tStep [200/500], Loss: 1.7484\n",
      "\t\t\t\tStep [300/500], Loss: 1.7674\n",
      "\t\t\t\tStep [400/500], Loss: 1.8409\n",
      "\t\t\t\tStep [500/500], Loss: 1.8219\n",
      "      test_error = 1.1528140168190002, accuracy = 75.9%\n",
      "Regroup-10 Epoch-48\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7375\n",
      "\t\t\t\tStep [200/500], Loss: 1.8527\n",
      "\t\t\t\tStep [300/500], Loss: 1.8927\n",
      "\t\t\t\tStep [400/500], Loss: 2.0378\n",
      "\t\t\t\tStep [500/500], Loss: 1.9407\n",
      "      test_error = 1.3808859086990357, accuracy = 73.45%\n",
      "Regroup-10 Epoch-49\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8375\n",
      "\t\t\t\tStep [200/500], Loss: 1.8928\n",
      "\t\t\t\tStep [300/500], Loss: 1.7618\n",
      "\t\t\t\tStep [400/500], Loss: 1.8616\n",
      "\t\t\t\tStep [500/500], Loss: 1.9340\n",
      "      test_error = 1.1703486970901489, accuracy = 76.24%\n",
      "Regroup-11 Epoch-50\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8716\n",
      "\t\t\t\tStep [200/500], Loss: 1.7532\n",
      "\t\t\t\tStep [300/500], Loss: 1.9067\n",
      "\t\t\t\tStep [400/500], Loss: 1.7260\n",
      "\t\t\t\tStep [500/500], Loss: 1.7804\n",
      "      test_error = 1.2998819465637208, accuracy = 74.55000000000001%\n",
      "Regroup-11 Epoch-51\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8963\n",
      "\t\t\t\tStep [200/500], Loss: 1.7754\n",
      "\t\t\t\tStep [300/500], Loss: 1.8776\n",
      "\t\t\t\tStep [400/500], Loss: 1.8323\n",
      "\t\t\t\tStep [500/500], Loss: 1.9222\n",
      "      test_error = 1.2944049432754516, accuracy = 74.99%\n",
      "Regroup-11 Epoch-52\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9407\n",
      "\t\t\t\tStep [200/500], Loss: 1.8046\n",
      "\t\t\t\tStep [300/500], Loss: 1.9418\n",
      "\t\t\t\tStep [400/500], Loss: 1.7784\n",
      "\t\t\t\tStep [500/500], Loss: 1.8302\n",
      "      test_error = 1.5010773006439209, accuracy = 72.75%\n",
      "Regroup-11 Epoch-53\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8675\n",
      "\t\t\t\tStep [200/500], Loss: 1.8033\n",
      "\t\t\t\tStep [300/500], Loss: 1.9176\n",
      "\t\t\t\tStep [400/500], Loss: 1.7769\n",
      "\t\t\t\tStep [500/500], Loss: 1.7604\n",
      "      test_error = 1.302688869857788, accuracy = 75.2%\n",
      "Regroup-11 Epoch-54\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8194\n",
      "\t\t\t\tStep [200/500], Loss: 1.8490\n",
      "\t\t\t\tStep [300/500], Loss: 1.8505\n",
      "\t\t\t\tStep [400/500], Loss: 1.8837\n",
      "\t\t\t\tStep [500/500], Loss: 1.8550\n",
      "      test_error = 1.5162161840438844, accuracy = 73.04%\n",
      "Regroup-12 Epoch-55\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.6932\n",
      "\t\t\t\tStep [200/500], Loss: 1.7749\n",
      "\t\t\t\tStep [300/500], Loss: 1.7076\n",
      "\t\t\t\tStep [400/500], Loss: 1.7099\n",
      "\t\t\t\tStep [500/500], Loss: 1.8272\n",
      "      test_error = 1.5584804724693297, accuracy = 73.00999999999999%\n",
      "Regroup-12 Epoch-56\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8286\n",
      "\t\t\t\tStep [200/500], Loss: 1.8234\n",
      "\t\t\t\tStep [300/500], Loss: 1.8378\n",
      "\t\t\t\tStep [400/500], Loss: 1.8914\n",
      "\t\t\t\tStep [500/500], Loss: 1.8616\n",
      "      test_error = 1.3532723868727683, accuracy = 75.31%\n",
      "Regroup-12 Epoch-57\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8062\n",
      "\t\t\t\tStep [200/500], Loss: 1.7136\n",
      "\t\t\t\tStep [300/500], Loss: 1.8085\n",
      "\t\t\t\tStep [400/500], Loss: 1.8426\n",
      "\t\t\t\tStep [500/500], Loss: 1.8800\n",
      "      test_error = 1.3756086912155152, accuracy = 74.19%\n",
      "Regroup-12 Epoch-58\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7199\n",
      "\t\t\t\tStep [200/500], Loss: 1.7961\n",
      "\t\t\t\tStep [300/500], Loss: 1.7176\n",
      "\t\t\t\tStep [400/500], Loss: 1.8215\n",
      "\t\t\t\tStep [500/500], Loss: 1.8556\n",
      "      test_error = 1.5420786551475525, accuracy = 73.38%\n",
      "Regroup-12 Epoch-59\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7750\n",
      "\t\t\t\tStep [200/500], Loss: 1.7426\n",
      "\t\t\t\tStep [300/500], Loss: 1.7901\n",
      "\t\t\t\tStep [400/500], Loss: 1.8908\n",
      "\t\t\t\tStep [500/500], Loss: 1.7719\n",
      "      test_error = 1.2738466665267945, accuracy = 76.25999999999999%\n",
      "Regroup-13 Epoch-60\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7860\n",
      "\t\t\t\tStep [200/500], Loss: 1.7522\n",
      "\t\t\t\tStep [300/500], Loss: 1.7670\n",
      "\t\t\t\tStep [400/500], Loss: 1.7916\n",
      "\t\t\t\tStep [500/500], Loss: 1.9000\n",
      "      test_error = 1.5081999423980712, accuracy = 74.09%\n",
      "Regroup-13 Epoch-61\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7932\n",
      "\t\t\t\tStep [200/500], Loss: 1.8283\n",
      "\t\t\t\tStep [300/500], Loss: 1.8258\n",
      "\t\t\t\tStep [400/500], Loss: 1.8123\n",
      "\t\t\t\tStep [500/500], Loss: 1.8509\n",
      "      test_error = 1.5702985632419586, accuracy = 74.6%\n",
      "Regroup-13 Epoch-62\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7990\n",
      "\t\t\t\tStep [200/500], Loss: 1.9019\n",
      "\t\t\t\tStep [300/500], Loss: 1.7919\n",
      "\t\t\t\tStep [400/500], Loss: 1.6957\n",
      "\t\t\t\tStep [500/500], Loss: 1.8538\n",
      "      test_error = 1.460776002597809, accuracy = 75.2%\n",
      "Regroup-13 Epoch-63\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7210\n",
      "\t\t\t\tStep [200/500], Loss: 1.8041\n",
      "\t\t\t\tStep [300/500], Loss: 1.8537\n",
      "\t\t\t\tStep [400/500], Loss: 1.9217\n",
      "\t\t\t\tStep [500/500], Loss: 1.8286\n",
      "      test_error = 1.7478914184570313, accuracy = 72.55%\n",
      "Regroup-13 Epoch-64\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8235\n",
      "\t\t\t\tStep [200/500], Loss: 1.7965\n",
      "\t\t\t\tStep [300/500], Loss: 1.6677\n",
      "\t\t\t\tStep [400/500], Loss: 1.9771\n",
      "\t\t\t\tStep [500/500], Loss: 1.9636\n",
      "      test_error = 1.4517426719665527, accuracy = 75.27000000000001%\n",
      "Regroup-14 Epoch-65\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7983\n",
      "\t\t\t\tStep [200/500], Loss: 1.8446\n",
      "\t\t\t\tStep [300/500], Loss: 1.8884\n",
      "\t\t\t\tStep [400/500], Loss: 1.8765\n",
      "\t\t\t\tStep [500/500], Loss: 2.0175\n",
      "      test_error = 1.508811958217621, accuracy = 75.2%\n",
      "Regroup-14 Epoch-66\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7034\n",
      "\t\t\t\tStep [200/500], Loss: 2.0269\n",
      "\t\t\t\tStep [300/500], Loss: 1.8516\n",
      "\t\t\t\tStep [400/500], Loss: 1.9092\n",
      "\t\t\t\tStep [500/500], Loss: 1.7744\n",
      "      test_error = 1.4314473601341247, accuracy = 75.31%\n",
      "Regroup-14 Epoch-67\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7842\n",
      "\t\t\t\tStep [200/500], Loss: 1.8123\n",
      "\t\t\t\tStep [300/500], Loss: 1.8150\n",
      "\t\t\t\tStep [400/500], Loss: 1.9098\n",
      "\t\t\t\tStep [500/500], Loss: 1.8042\n",
      "      test_error = 1.5436773553848266, accuracy = 74.31%\n",
      "Regroup-14 Epoch-68\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9189\n",
      "\t\t\t\tStep [200/500], Loss: 1.7418\n",
      "\t\t\t\tStep [300/500], Loss: 1.7971\n",
      "\t\t\t\tStep [400/500], Loss: 1.9635\n",
      "\t\t\t\tStep [500/500], Loss: 1.7507\n",
      "      test_error = 1.501591660118103, accuracy = 74.00999999999999%\n",
      "Regroup-14 Epoch-69\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9055\n",
      "\t\t\t\tStep [200/500], Loss: 1.8130\n",
      "\t\t\t\tStep [300/500], Loss: 1.8453\n",
      "\t\t\t\tStep [400/500], Loss: 1.8710\n",
      "\t\t\t\tStep [500/500], Loss: 1.7497\n",
      "      test_error = 1.5493193713188171, accuracy = 73.95%\n",
      "Regroup-15 Epoch-70\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8271\n",
      "\t\t\t\tStep [200/500], Loss: 1.8408\n",
      "\t\t\t\tStep [300/500], Loss: 1.7065\n",
      "\t\t\t\tStep [400/500], Loss: 1.9500\n",
      "\t\t\t\tStep [500/500], Loss: 1.7093\n",
      "      test_error = 1.4851696617126464, accuracy = 75.38%\n",
      "Regroup-15 Epoch-71\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7046\n",
      "\t\t\t\tStep [200/500], Loss: 1.8122\n",
      "\t\t\t\tStep [300/500], Loss: 1.7468\n",
      "\t\t\t\tStep [400/500], Loss: 1.8797\n",
      "\t\t\t\tStep [500/500], Loss: 1.8115\n",
      "      test_error = 1.6281373399734498, accuracy = 74.83999999999999%\n",
      "Regroup-15 Epoch-72\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.6066\n",
      "\t\t\t\tStep [200/500], Loss: 1.6696\n",
      "\t\t\t\tStep [300/500], Loss: 1.9557\n",
      "\t\t\t\tStep [400/500], Loss: 1.8330\n",
      "\t\t\t\tStep [500/500], Loss: 1.7343\n",
      "      test_error = 1.624112438392639, accuracy = 75.08%\n",
      "Regroup-15 Epoch-73\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9053\n",
      "\t\t\t\tStep [200/500], Loss: 1.7858\n",
      "\t\t\t\tStep [300/500], Loss: 1.9212\n",
      "\t\t\t\tStep [400/500], Loss: 1.7739\n",
      "\t\t\t\tStep [500/500], Loss: 1.7860\n",
      "      test_error = 1.5256511119842529, accuracy = 75.35%\n",
      "Regroup-15 Epoch-74\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8375\n",
      "\t\t\t\tStep [200/500], Loss: 1.7851\n",
      "\t\t\t\tStep [300/500], Loss: 1.7816\n",
      "\t\t\t\tStep [400/500], Loss: 1.6764\n",
      "\t\t\t\tStep [500/500], Loss: 1.8717\n",
      "      test_error = 1.3906070951461793, accuracy = 76.16000000000001%\n",
      "Regroup-16 Epoch-75\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8285\n",
      "\t\t\t\tStep [200/500], Loss: 1.8887\n",
      "\t\t\t\tStep [300/500], Loss: 1.8083\n",
      "\t\t\t\tStep [400/500], Loss: 1.7876\n",
      "\t\t\t\tStep [500/500], Loss: 1.7912\n",
      "      test_error = 1.5826778190612794, accuracy = 74.71%\n",
      "Regroup-16 Epoch-76\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7111\n",
      "\t\t\t\tStep [200/500], Loss: 1.9201\n",
      "\t\t\t\tStep [300/500], Loss: 1.9228\n",
      "\t\t\t\tStep [400/500], Loss: 1.8205\n",
      "\t\t\t\tStep [500/500], Loss: 1.8386\n",
      "      test_error = 1.503524910926819, accuracy = 75.47%\n",
      "Regroup-16 Epoch-77\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7367\n",
      "\t\t\t\tStep [200/500], Loss: 1.8887\n",
      "\t\t\t\tStep [300/500], Loss: 1.9335\n",
      "\t\t\t\tStep [400/500], Loss: 1.7914\n",
      "\t\t\t\tStep [500/500], Loss: 1.8927\n",
      "      test_error = 1.4891227987289428, accuracy = 76.28%\n",
      "Regroup-16 Epoch-78\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.6703\n",
      "\t\t\t\tStep [200/500], Loss: 1.7700\n",
      "\t\t\t\tStep [300/500], Loss: 1.7030\n",
      "\t\t\t\tStep [400/500], Loss: 1.8133\n",
      "\t\t\t\tStep [500/500], Loss: 1.7823\n",
      "      test_error = 1.5444, accuracy = 75.09%\n",
      "Regroup-16 Epoch-79\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7560\n",
      "\t\t\t\tStep [200/500], Loss: 1.6458\n",
      "\t\t\t\tStep [300/500], Loss: 1.8036\n",
      "\t\t\t\tStep [400/500], Loss: 1.7371\n",
      "\t\t\t\tStep [500/500], Loss: 1.7664\n",
      "      test_error = 1.5346494688034058, accuracy = 75.7%\n",
      "Regroup-17 Epoch-80\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7515\n",
      "\t\t\t\tStep [200/500], Loss: 1.9905\n",
      "\t\t\t\tStep [300/500], Loss: 1.6783\n",
      "\t\t\t\tStep [400/500], Loss: 1.6183\n",
      "\t\t\t\tStep [500/500], Loss: 1.7659\n",
      "      test_error = 1.439412340927124, accuracy = 76.62%\n",
      "Regroup-17 Epoch-81\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8391\n",
      "\t\t\t\tStep [200/500], Loss: 1.6671\n",
      "\t\t\t\tStep [300/500], Loss: 1.8012\n",
      "\t\t\t\tStep [400/500], Loss: 1.8026\n",
      "\t\t\t\tStep [500/500], Loss: 1.8260\n",
      "      test_error = 1.6528400472640992, accuracy = 74.89%\n",
      "Regroup-17 Epoch-82\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8234\n",
      "\t\t\t\tStep [200/500], Loss: 1.7082\n",
      "\t\t\t\tStep [300/500], Loss: 1.7682\n",
      "\t\t\t\tStep [400/500], Loss: 1.7155\n",
      "\t\t\t\tStep [500/500], Loss: 1.6472\n",
      "      test_error = 1.551103831100464, accuracy = 76.46%\n",
      "Regroup-17 Epoch-83\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.6640\n",
      "\t\t\t\tStep [200/500], Loss: 1.7454\n",
      "\t\t\t\tStep [300/500], Loss: 1.7789\n",
      "\t\t\t\tStep [400/500], Loss: 1.7394\n",
      "\t\t\t\tStep [500/500], Loss: 1.8153\n",
      "      test_error = 1.686386922264099, accuracy = 75.29%\n",
      "Regroup-17 Epoch-84\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8812\n",
      "\t\t\t\tStep [200/500], Loss: 1.8603\n",
      "\t\t\t\tStep [300/500], Loss: 1.7257\n",
      "\t\t\t\tStep [400/500], Loss: 1.8072\n",
      "\t\t\t\tStep [500/500], Loss: 1.6814\n",
      "      test_error = 1.597957399368286, accuracy = 75.72%\n",
      "Regroup-18 Epoch-85\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7814\n",
      "\t\t\t\tStep [200/500], Loss: 1.8739\n",
      "\t\t\t\tStep [300/500], Loss: 1.6993\n",
      "\t\t\t\tStep [400/500], Loss: 1.8587\n",
      "\t\t\t\tStep [500/500], Loss: 1.6898\n",
      "      test_error = 1.51248486328125, accuracy = 76.0%\n",
      "Regroup-18 Epoch-86\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7437\n",
      "\t\t\t\tStep [200/500], Loss: 1.7947\n",
      "\t\t\t\tStep [300/500], Loss: 1.8579\n",
      "\t\t\t\tStep [400/500], Loss: 1.7780\n",
      "\t\t\t\tStep [500/500], Loss: 1.8057\n",
      "      test_error = 1.5584728672027588, accuracy = 75.14%\n",
      "Regroup-18 Epoch-87\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7079\n",
      "\t\t\t\tStep [200/500], Loss: 1.9111\n",
      "\t\t\t\tStep [300/500], Loss: 1.7236\n",
      "\t\t\t\tStep [400/500], Loss: 1.5740\n",
      "\t\t\t\tStep [500/500], Loss: 1.7870\n",
      "      test_error = 1.796051012802124, accuracy = 73.72%\n",
      "Regroup-18 Epoch-88\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7474\n",
      "\t\t\t\tStep [200/500], Loss: 1.7189\n",
      "\t\t\t\tStep [300/500], Loss: 1.7523\n",
      "\t\t\t\tStep [400/500], Loss: 1.7145\n",
      "\t\t\t\tStep [500/500], Loss: 1.8030\n",
      "      test_error = 1.5298327045440674, accuracy = 76.29%\n",
      "Regroup-18 Epoch-89\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7705\n",
      "\t\t\t\tStep [200/500], Loss: 1.8422\n",
      "\t\t\t\tStep [300/500], Loss: 1.7377\n",
      "\t\t\t\tStep [400/500], Loss: 1.6839\n",
      "\t\t\t\tStep [500/500], Loss: 1.7805\n",
      "      test_error = 1.8714551818847656, accuracy = 73.0%\n",
      "Regroup-19 Epoch-90\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7020\n",
      "\t\t\t\tStep [200/500], Loss: 1.7495\n",
      "\t\t\t\tStep [300/500], Loss: 1.6754\n",
      "\t\t\t\tStep [400/500], Loss: 1.7186\n",
      "\t\t\t\tStep [500/500], Loss: 1.7545\n",
      "      test_error = 1.6932062852859497, accuracy = 75.64999999999999%\n",
      "Regroup-19 Epoch-91\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.8526\n",
      "\t\t\t\tStep [200/500], Loss: 1.8973\n",
      "\t\t\t\tStep [300/500], Loss: 1.8067\n",
      "\t\t\t\tStep [400/500], Loss: 1.7509\n",
      "\t\t\t\tStep [500/500], Loss: 1.7194\n",
      "      test_error = 1.6927644298553466, accuracy = 73.79%\n",
      "Regroup-19 Epoch-92\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7286\n",
      "\t\t\t\tStep [200/500], Loss: 1.7139\n",
      "\t\t\t\tStep [300/500], Loss: 1.7099\n",
      "\t\t\t\tStep [400/500], Loss: 1.8279\n",
      "\t\t\t\tStep [500/500], Loss: 1.6819\n",
      "      test_error = 1.5360182595252991, accuracy = 74.99%\n",
      "Regroup-19 Epoch-93\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7639\n",
      "\t\t\t\tStep [200/500], Loss: 1.8819\n",
      "\t\t\t\tStep [300/500], Loss: 1.7029\n",
      "\t\t\t\tStep [400/500], Loss: 1.7779\n",
      "\t\t\t\tStep [500/500], Loss: 1.8787\n",
      "      test_error = 1.6593886144638061, accuracy = 74.86%\n",
      "Regroup-19 Epoch-94\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7791\n",
      "\t\t\t\tStep [200/500], Loss: 1.8117\n",
      "\t\t\t\tStep [300/500], Loss: 1.8393\n",
      "\t\t\t\tStep [400/500], Loss: 1.7975\n",
      "\t\t\t\tStep [500/500], Loss: 1.8147\n",
      "      test_error = 2.017048572921753, accuracy = 71.95%\n",
      "Regroup-20 Epoch-95\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.6440\n",
      "\t\t\t\tStep [200/500], Loss: 1.7381\n",
      "\t\t\t\tStep [300/500], Loss: 1.7271\n",
      "\t\t\t\tStep [400/500], Loss: 1.7339\n",
      "\t\t\t\tStep [500/500], Loss: 1.7498\n",
      "      test_error = 1.8120385543823243, accuracy = 73.6%\n",
      "Regroup-20 Epoch-96\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7556\n",
      "\t\t\t\tStep [200/500], Loss: 1.8780\n",
      "\t\t\t\tStep [300/500], Loss: 1.7235\n",
      "\t\t\t\tStep [400/500], Loss: 1.7326\n",
      "\t\t\t\tStep [500/500], Loss: 1.7954\n",
      "      test_error = 1.794557554626465, accuracy = 74.38%\n",
      "Regroup-20 Epoch-97\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7512\n",
      "\t\t\t\tStep [200/500], Loss: 1.7251\n",
      "\t\t\t\tStep [300/500], Loss: 1.6681\n",
      "\t\t\t\tStep [400/500], Loss: 1.7469\n",
      "\t\t\t\tStep [500/500], Loss: 1.8241\n",
      "      test_error = 1.844553003692627, accuracy = 73.8%\n",
      "Regroup-20 Epoch-98\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.9491\n",
      "\t\t\t\tStep [200/500], Loss: 1.7939\n",
      "\t\t\t\tStep [300/500], Loss: 1.7641\n",
      "\t\t\t\tStep [400/500], Loss: 1.7512\n",
      "\t\t\t\tStep [500/500], Loss: 1.9004\n",
      "      test_error = 1.7974378162384033, accuracy = 74.64%\n",
      "Regroup-20 Epoch-99\n",
      "\t\tlr: 0.0001\n",
      "\t\t\t\tStep [100/500], Loss: 1.7210\n",
      "\t\t\t\tStep [200/500], Loss: 1.8627\n",
      "\t\t\t\tStep [300/500], Loss: 1.6328\n",
      "\t\t\t\tStep [400/500], Loss: 1.7673\n",
      "\t\t\t\tStep [500/500], Loss: 1.7564\n",
      "      test_error = 1.8631241908073426, accuracy = 74.26%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),  # mean-std of cifar10\n",
    "        ])\n",
    "transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),  # mean-std of cifar10\n",
    "        ])\n",
    "\n",
    "train_batch_size = 64\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\".\", train=False, transform=transform_test, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=256, shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "image_size = 32\n",
    "in_channel = 3\n",
    "\n",
    "model = WideResNet(depth=22, widen_factor=8, dropout_rate=0.3, num_classes=n_classes, in_channel=in_channel, image_size=image_size).to(device)\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "total_epochs = 100\n",
    "num_epoch_regroup = 5\n",
    "noisy_prior_choice = \"approx\"  # change it to \"uniform\" to use LLPFC-uniform\n",
    "weights = \"uniform\"\n",
    "\n",
    "num_regroup = 0\n",
    "for epoch in range(total_epochs):\n",
    "        if epoch % num_epoch_regroup == 0:\n",
    "            instance2group, group2transition, instance2weight, noisy_y = make_groups_forward(n_classes,\n",
    "                                                                                             bag2indices,\n",
    "                                                                                             bag2size,\n",
    "                                                                                             bag2prop,\n",
    "                                                                                             noisy_prior_choice,\n",
    "                                                                                             weights)\n",
    "            fc_train_dataset = FORWARD_CORRECT_CIFAR10(training_data,\n",
    "                                                        noisy_y,\n",
    "                                                        group2transition,\n",
    "                                                        instance2weight,\n",
    "                                                        instance2group,\n",
    "                                                        transform_train)\n",
    "            llp_train_loader = torch.utils.data.DataLoader(dataset=fc_train_dataset, shuffle=True,\n",
    "                                                               batch_size=train_batch_size)\n",
    "            num_regroup += 1\n",
    "        print(f\"Regroup-{num_regroup} Epoch-{epoch}\")\n",
    "        print(f\"\t\tlr: {optimizer.param_groups[0]['lr']}\")\n",
    "        train_model_forward_one_epoch(model, loss_f, optimizer, llp_train_loader, device, epoch, None)\n",
    "        acc, test_error = test_model(model, test_loader, loss_f_test, device)\n",
    "        print(f\"      test_error = {test_error}, accuracy = {100 * acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1676916674131,
     "user": {
      "displayName": "JX Z",
      "userId": "11959735338320227911"
     },
     "user_tz": 300
    },
    "id": "3A-3DQld4ylX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPc1BporpQMmmqLHTUpG63B",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
