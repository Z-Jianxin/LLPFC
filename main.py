import argparse
from llpfc import llpfc

def get_args():
    parser = argparse.ArgumentParser(description="train a model on LLP data")
    # required:
    parser.add_argument("-d", "--dataset", nargs='?', choices=["cifar10"], required=True,
                        help="name of the dataset, the program uses torchvision.datasets")  # ToDo: add more data sets later
    parser.add_argument("-p", "--path_lp", nargs='?', required=True,
                        help="path to the label proportion dataset generated by make_data.py")
    parser.add_argument("-c", "--num_classes", nargs='?', type=int, required=True, metavar="10",
                        help="number of classes")
    parser.add_argument("-f", "--data_folder_labeled", nargs='?', required=True,
                        help="path to the folder of labeled test data, if not exists, the dataset will be downloaded")

    # optional:
    parser.add_argument("-a", "--algorithm", nargs='?', choices=["llpfc"], default="llpfc",
                        help="choose a training algorithm")  # ToDo: add more after implementing competitors
    parser.add_argument("-n", "--network", nargs='?', choices=["wide_resnet_28_2", "nin"],
                        default="wide_resnet_28_2", help="the neural network model")  # ToDo: include more networks
    parser.add_argument("--drop_rate", nargs="?", type=float, default=0.3,
                        help="the drop rate in dropout layers, for wide resnet")  # add more to this
    parser.add_argument("-o", "--optimizer", nargs="?", default="Adamax",
                        choices=["Adamax", "LBFGS", "Adagrad", "nesterov"],
                        help="optimizer of the neural network")
    parser.add_argument("-l", "--lr", nargs="?", type=float, default=1e-3, help="learning rate")
    parser.add_argument("-m", "--momentum", nargs="?", type=float, default=0.9, help="momentum")
    parser.add_argument("-w", "--weight_decay", nargs="?", type=float, default=0, help="weight decay")
    parser.add_argument("-e", "--total_epochs", nargs="?", type=int, default=400,
                        help="total number of epochs to train")
    parser.add_argument("-r", "--num_epoch_regroup", nargs="?", type=int, default=20,
                        help="groups will be regenerated every this number of epochs, " 
                             "only effective if the algorithm is llpfc")
    parser.add_argument("-v", "--validate", nargs='?', type=bool, default=False,
                        help="if True, then validate on 10%% of the training data set; " 
                             "if False, output testing loss and accuracy will training")
    parser.add_argument("-b", "--train_batch_size", nargs='?', type=int, default=128, help="training batch size")
    parser.add_argument("-t", "--test_batch_size", nargs="?", type=int, default=256, help="test batch size")
    parser.add_argument("-s", "--save_path", nargs='?', default=None,
                        help="path to save the trained model, model will not be saved if the path is None")
    parser.add_argument("-g", "--device", nargs='?', default="check", choices=["cuda", "cpu", "check"],
                        help="device to train network; if it's check, use cuda whenever it's available")
    parser.add_argument("--seed", nargs='?', type=int, metavar="0", help="seed for all RNG")
    parser.add_argument("--full_reproducibility", nargs='?', type=bool, default=False,
                        help="choose to disable all nondeterministic algorithms, may at the cost of performance")
    return parser.parse_args()


def main(args):
    if args.algorithm == "llpfc":
        llpfc(args)


if __name__ == "__main__":
    args = get_args()
    main(args)